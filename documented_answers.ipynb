{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to identify the person who have conducted frauds in the Enron event. In machine learning language, we are trying to classify the persons involved into two categories: persons of interest and persons not of interest. There are many machine learning algorithms that can potentially solve this classification problem based on the features provided, such as the financial features and the email features. In this data set, there are 145 people, and 19 of them have been labeled as person of interest. There are 14 financial features, which show the salaries and related finanical activieis, and 6 email features, which shows the interactions among those 146 people. Among the email features, the 'email_address' is irrelevant and will be deleted. **Thus, 18 features are left.** As shown in poi_id_help file, **besides the row 'TOTAL' (which has been deleted right in the beginning, see line 43 in poi_id.py)**, there are some other outliers available in the data set, and they are 'LAY KENNETH L' for both 'loan_advances' and 'total_payments', and 'BHATNAGAR SANJAY' for 'restricted_stock_deferred'. Among those three persons, 'LAY KENNETH L' is a poi, and I do not want to delete this person. Thus, instead of removing rows, I will not use the features that have outliers. This approach is risky in that the outliers or the features with outliers themselves could be strong indicators during the classification, but for now I will take the risk, since we have a lot other features that could do the job. **Thus, so far 16 features left.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to use two new features: \n",
    "1. the ratio of 'to_messages' and 'from_messages'\n",
    "2. the ratio of 'from_poi_to_this_person' and 'from_this_person_to_poi'\n",
    "The reason is that pois tend to be more powerful, and they receive more emails than they send.\n",
    "\n",
    "In this way, put together this two new features with the previous 16 features, giving us 18 features. Since different features have different range of values, I rescale all the features to be in [0,1] **(in the code, Min_Max_scaler is used)** with the following formula \n",
    "\\begin{align}\n",
    "\\textrm{new_array} = \\frac{\\textrm{old_array-min(old_array)}}{\\textrm{max(old_array)-min(old_array)}}\n",
    "\\end{align}\n",
    "\n",
    "I use **SelectKBest** to do the feature selection with the two new features, and the result is\n",
    "```\n",
    "print select.scores_\n",
    "\n",
    "[ 18.57570327\n",
    "   0.21705893\n",
    "   21.06000171\n",
    "   11.59554766\n",
    "   24.46765405\n",
    "   6.23420114\n",
    "   25.09754153\n",
    "   4.20497086\n",
    "   10.07245453\n",
    "   9.34670079\n",
    "   2.10765594\n",
    "   8.74648553\n",
    "   1.69882435\n",
    "   0.1641645\n",
    "   5.34494152\n",
    "   2.42650813\n",
    "   5.55502427\n",
    "   0.42324423]\n",
    "```\n",
    "This scores correspond to the features in the same order as follows\n",
    "```\n",
    "\n",
    " 'salary',                  # feature 1\n",
    " 'deferral_payments',       # feature 2\n",
    " 'bonus',                   # feature 3\n",
    " 'deferred_income',         # feature 4\n",
    " 'total_stock_value',       # feature 5\n",
    " 'expenses',                # feature 6\n",
    " 'exercised_stock_options', # feature 7\n",
    " 'other',                   # feature 8\n",
    " 'long_term_incentive',     # feature 9\n",
    " 'restricted_stock',        # feature 10\n",
    " 'director_fees',           # feature 11\n",
    " 'shared_receipt_with_poi', # feature 12\n",
    " 'to_messages',             # feature 13\n",
    " 'from_messages',           # feature 14\n",
    " 'from_poi_to_this_person', # feature 15\n",
    " 'from_this_person_to_poi'] # feature 16\n",
    " 'new feature 1'            # feature 17\n",
    " 'new feature 2'            # feature 18\n",
    "```\n",
    "It seems that the first new feature (second last in the list)--the ratio of 'to_messages' and 'from_messages'--has a much higher score than the second new feature (last in the list)--the ratio of 'from_poi_to_this_person' and 'from_this_person_to_poi'--. This is a bit surprising, and I do not know why there is this much difference. However, if we look at scores of the original four features, features 13, 14, 15, and 16, it can be seen that features 13 and 14 are not important although their ratio is import, and feature 15 is important although its ratio to feature 16 is not important. We will see what will happen if I delete the two new features, since I will not use them in the final model.\n",
    "\n",
    "Without the two new features, I do the **SelectKBest** again\n",
    "```\n",
    "print select.scores_\n",
    "[ 18.57570327\n",
    "   0.21705893\n",
    "   21.06000171\n",
    "   11.59554766\n",
    "   24.46765405\n",
    "   6.23420114\n",
    "   25.09754153\n",
    "   4.20497086\n",
    "   10.07245453\n",
    "   9.34670079\n",
    "   2.10765594\n",
    "   8.74648553\n",
    "   1.69882435\n",
    "   0.1641645\n",
    "   5.34494152\n",
    "   2.42650813]\n",
    "```\n",
    "This correponds to the first 16 features in the feature list above. It can be seen that features 13, 14, 15 and 16 have roughly the same values as above. If we plot the sorted select.scores (shown below), we can see that there is a big drop after the first 4 features with high scores. However, in the GridSearchCV, I passed three different feature numbers (k), 4, 5, and 10, and **'k = 5' gives the best fit under GaussianNB**. Thus, the top 5 features seems a better choice than the top 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFmFJREFUeJzt3X+QXWd93/H3x0giC0bGuIsVMN4NbokYGsU4HUrjAV8B\nrpWk2AydGsy0YHAz0CRAAzQY+kOCpq3jSZ1xh2iaDIIaWguDScBmAhjH3jDQoYgfrmxsSBpY2Q5Y\nbLD5VdRYxN/+cc861+uVtHf37p67Z9+vmTu695x7nvPVavXZZ5/znOemqpAkdcdJbRcgSRotg12S\nOsZgl6SOMdglqWMMdknqGINdkjrGYNe6kWQqyUNJ/L6VjsP/IFpvVnzjRZJvJHnBKIqRxpHBLq2x\nJI9puwZ1m8GuViR5a5J7k3w/yV1Jdjbbk+TyJP8nyVySDyR54jHa2Jrk3Um+meSeJP8+SQb2/3KS\nO5tz3JHk7CTvA84Ebmy2v2WRdk9LcmOSB5J8J8mfDOw7I8mHk3y7qe+/DNT9b5LMJrkvyX9LsrXZ\nNz+E9Jokh4A/brY/N8lnm/N8Ocl5I/wSawMz2LXmkjwD+FXg56pqK3ABMNvsfgNwIfA84CnAA8De\nYzR1DfAg8HTg2cD5wD9vzvFPgH8H/NPmHBcC36mqVwJ3A/+oqrZW1W8v0u6bgXuA04AnA29v2jwJ\n+BjwDfo/HJ4KfKA55tXAK4HzmnqeALxrQbvPB7YDFyR5StPWO6vqVOAtwIeTnHasr5u0ZFXlw8ea\nPoCzgPuAFwKbFuy7E9g58Pon6Yf3ScAU8NfN89OB/wc8duC9Lwf+uHn+CeD1xzj/N4AXHKe+dwB/\nCJy1YPtzgcPASYscczPwuoHXz1ik7qmB/b8BXLOgjU8A/6ztfx8f6/9hj11rrqr+HPiXwB7gcJJr\nk2xrdk8Bf5jk/iT30w/6o/SDfNCZwGbgW817HwD+KzDZ7H8a8OfLLPHK5tibmiGhtw60eaiqHlrk\nmKcAhwZeHwI2Laj73oHnU8DF83/Ppv5z6f8gk1bEYFcrquoDVfU8+gEH8FvNn3cDv1BVT2oep1bV\n46vqWwuauId+j/20gfc9sap2DOw/61inP0Ft/7eq3lJVZ9EfwnlTcw3gHuDMY0y3/ObA34Xm+VH6\nPfzFznsP8L4Ff88nVNWVx6tNWgqDXWsuyTOS7Eyyhf5wxRFgvhf8e8B/THJm897JJBcOHg5QVfcB\nNwG/k+QJzcXLpyd5fvO+dwNvSXJO085ZSZ7W7DtMfxz8WPX9UpL5Hwo/AH7c1Pd54FvAFUkel+Sx\nSX6+ed9+4NeTTCc5GfgPwAcGevfhkf478OIk/zDJSUl+Isl5zdi7tCIGu9rwWOAKYI5+T3cSeFuz\n72rgo/SHQb4H/E/gOQPHDvZ6XwlsoT9ccz/wIWAbQFVdTz9cr03yffpj5k9qjvtPwL9thkDetEh9\nfwe4OckPgM8Cv1tVf9KE9Iub/XfT73Vf3BzzHuD9wKfpD+P8iP6F4MXqpqruBS6if2F2jv7QzVvw\n/6RGIFVLu98jyWPpf9NuoT92eH1VvSPJqcB19H/1nAUurqrvrU65kqQTWXKwAyR5XFX9qLnB4rP0\neyT/mP40siubi0ynVtXlq1OuJOlEhvq1r6p+1Dx9LP1ee9H/dfKaZvs1wEtGVp0kaWhDBXtzkefL\n9Ocgf6qqDgCnV9VhePiC1pNHX6YkaamG7bE/VFXPBs4AnpPkWTx66pifji1JLdq0nIOq6vtJZoBd\n9G8wOb2qDjc3mXx7sWOSGPiStAxVtXC67HEtucee5G8lOaV5PkF/XY67gBuAS5u3vYr+VLVjFTdW\nj927d7dew3qoaVzrsiZr2gh1LccwPfafBK5p7ro7Cbiuqv4oyeeADyZ5Df25uBcfrxFJ0upacrBX\n1e3AOYtsvx940SiLkiQt34a+y63X67VdwqOMY00wnnVZ09JY09KNa13DGuoGpRWdKKm1OpckdUUS\narUunkqS1geDXZI6xmCXpI4x2CWpYwx2SeoYg12SOsZgl6SOMdglqWMMdknqGINdkjrGYJekjjHY\nJaljDHZJ6hiDXZI6xmCXpI4x2CWpYwx2SeoYg12SOsZgl6SOMdglqWMMdknqmCUHe5IzktyS5CtJ\nbk/y+mb77iT3JvlS89i1euVKkk4kVbW0NybbgG1VdVuSk4EvAhcBLwN+UFVXneD4Wuq51sLc3Byz\ns7NMT08zOTnZdjmStKgkVFWGOWbJPfaquq+qbmue/xC4C3jq/LmHOWnb9u+/jqmp7Zx//uuYmtrO\n/v3XtV2SJI3MknvsjzgomQZmgL8LvBm4FPge8AXgzVX1vUWOGYse+9zcHFNT2zly5FZgB3CQiYmd\nHDr0VXvuksbOcnrsm5ZxkpOB64E3VtUPk+wF3llVleQ3gauAyxY7ds+ePQ8/7/V69Hq9YU+/YrOz\ns2zZMs2RIzuaLTvYvHmK2dlZg11S62ZmZpiZmVlRG0P12JNsAj4GfLyqrl5k/xRwY1XtWGRfZ3vs\njtdLWi2rOsbeeA9w52CoNxdV570UuGPINtfU5OQk+/btZWJiJ1u3nsPExE727du77EB2vF7SuBlm\nVsy5wKeB24FqHm8HXgGcDTwEzAKvrarDixw/Fj32eaPoZTteL2m1reoYe1V9FnjMIrs+McwJx8Xk\n5OSKw9fxeknjyDtPV2B6epoHH5wFDjZbDnL06CGmp6fbK0rShmewr8Cox+slaRSWNY99WScaszH2\nUXJWjKTVspwxdoNdksbYWkx3lCSNOYNdkjrGYJekjjHYJaljDHZJ6hiDXZI6xmCXpI4x2CWpYwx2\nSeoYg12SOsZgl6SOMdglqWMMdknqGINdkjrGYB8jc3NzHDhwgLm5ubZLkbSOGexjYv/+65ia2s75\n57+Oqant7N9/XdslSVqn/KCNMTA3N8fU1HaOHLkV2AEcZGJiJ4cOfdVPZJI2OD9oY52anZ1ly5Zp\n+qEOsIPNm6eYnZ1tryhJ65bBPgamp6d58MFZ4GCz5SBHjx5ienq6vaIkrVtLDvYkZyS5JclXktye\n5A3N9lOT3JTka0k+meSU1Su3myYnJ9m3by8TEzvZuvUcJiZ2sm/fXodhJC3LksfYk2wDtlXVbUlO\nBr4IXAS8GvhOVV2Z5K3AqVV1+SLHO8Z+AnNzc8zOzjI9PW2oSwKWN8a+7IunST4CvKt5nFdVh5vw\nn6mq7Yu832CXpCGt2cXTJNPA2cDngNOr6jBAVd0HPHk5bUqSRmPTsAc0wzDXA2+sqh8mWdgNP2a3\nfM+ePQ8/7/V69Hq9YU8vSZ02MzPDzMzMitoYaigmySbgY8DHq+rqZttdQG9gKObWqnrmIsc6FCNJ\nQ1qLoZj3AHfOh3rjBuDS5vmrgI8O2aYkaYSGmRVzLvBp4Hb6wy0FvB34PPBB4GnAIeDiqvruIsfb\nY5ekIa3prJhhGeySNDyXFJAkGexd5RLA0sZlsHeQSwBLG5tj7B3jEsBStzjGLpcAlmSwd41LAEsy\n2DvGJYAlOcbeUS4BLHWDNyhJUsd48VSSZLBLUtcY7JLUMQa7JHWMwS5JHWOwS1LHGOyS1DEGuyR1\njMEuSR1jsEtSxxjsktQxBrskdYzBLkkdY7BLUscsOdiT7EtyOMnBgW27k9yb5EvNY9fqlClJWqph\neuzvBS5YZPtVVXVO8/jEiOqSJC3TkoO9qj4DPLDIrqEWgJckra5RjLH/WpLbkrw7ySkjaE+StAKb\nVnj8XuCdVVVJfhO4CrjsWG/es2fPw897vR69Xm+Fp5ekbpmZmWFmZmZFbQz1madJpoAbq2rHMPua\n/X7mqSQNaS0+8zQMjKkn2Taw76XAHUO2J0kasSUPxSS5FugBpyW5G9gN7ExyNvAQMAu8dhVqlCQN\nYaihmBWdyKEYSRraWgzFSJLGnMEuSR1jsEtSxxjsktQxBrskdYzBLkkdY7BLUscY7JLUMQa7JHWM\nwS5JHWOwS1LHGOyS1DEGuyR1jMEuSR1jsOuE5ubmOHDgAHNzc22XImkJDHYd1/791zE1tZ3zz38d\nU1Pb2b//urZLknQCftCGjmlubo6pqe0cOXIrsAM4yMTETg4d+iqTk5NtlydtCH7QhkZqdnaWLVum\n6Yc6wA42b55idna2vaIknZDBrmOanp7mwQdngYPNloMcPXqI6enp9oqSdEIGu45pcnKSffv2MjGx\nk61bz2FiYif79u11GEYac46x64Tm5uaYnZ1lenraUJfW2HLG2A12SRpjXjyVJC092JPsS3I4ycGB\nbacmuSnJ15J8Mskpq1OmJGmphumxvxe4YMG2y4Gbq+qngVuAt42qMHWPd7BKa2PJwV5VnwEeWLD5\nIuCa5vk1wEtGVJc6xjtYpbUz1MXTJFPAjVW1o3l9f1U9aWD/I14vONaLpxuUd7BKy7eci6ebRlzD\ncZN7z549Dz/v9Xr0er0Rn17jaP4O1iNHHn0Hq8EuPdLMzAwzMzMramOlPfa7gF5VHU6yDbi1qp55\njGPtsW9Qq9Fjd269Noq1mO6Y5jHvBuDS5vmrgI8O2Z42gFHfwep4vXR8S+6xJ7kW6AGnAYeB3cBH\ngA8BTwMOARdX1XePcbw99g1uFL1sx+u10azqGHtVveIYu140zAm1cU1OTq44fB2vl07MO0+1rox6\nxUnn1quLDHatK6Mcr3esXl3lImBal1Y6Xu9YvdaLcZjHLq2JlY7XO1avLnMoRhuSnw6lLjPYtSH5\n6VDqMsfYtaF5B6vGnZ+gJEkd4ycoSZIMdknqGoNdkjrGYJekjjHYJaljDHZJ6hiDXZI6xmCXpI4x\n2KURcW13jQuDXRoB13bXOHFJAWmFXNtdq8klBaQWzK/t3g91GFzbXWqDwS6tkGu7a9wY7NIKuba7\nxo1j7NKIjHJtd9eJ17zW1mNPMgt8D3gIOFpVz1nkPQa7tAT791/HZZf9Clu29Id49u3byyWXvKzt\nstSSNoP968DPVdUDx3mPwS6dgDNstFCbs2IywrakDcsZNhqFUYVxAZ9KciDJL4+oTWnDcYaNRmHT\niNo5t6q+lWSSfsDfVVWfWfimPXv2PPy81+vR6/VGdHqpG+Zn2Fx22U42b57i6NFDzrDZYGZmZpiZ\nmVlRGyOfFZNkN/CDqrpqwXbH2KUlclaM5rVy8TTJ44CTquqHSR4P3AS8o6puWvA+g11aY/6AWP/a\nunh6OvCZJF8GPgfcuDDUJa09FybbuLxBSeogp012h4uASQKcNrnRGexSBzltcmMz2KUOcmGyjc0x\ndqnDnBWz/rW2VsySTmSwS9LQvHgqSTLYJalrDHZJ6hiDXdKSzM3NceDAAebm5touRSdgsEs6IZcn\nWF+cFSPpuEa9PIFTMIfjrBhJIzfK5Qns+a8Ne+ySjmtUPXYXJlsee+ySRm5UyxOsxsJkXtBdnD12\nSUuy0rHxUffY9++/jssu+xW2bOkveLZv314uueRlQ7cz7lxSQNJYmw/jwc9zXU4Yb6RhneUE+6g+\nzFqSTuiSS17Gi170ghXPipkf1jly5NHDOl0L9uUw2CWtqcnJyRWH7yPXm+/32F1v/m948VTSuuN6\n88fnGLukdWsj3OzkxVNJ6hjnsUuSDHZJ6pqRBHuSXUm+muRPk7x1FG1K0loa1V2s43A37IqDPclJ\nwLuAC4BnAZck2b7SdiVprYxqcbJxWeRsxRdPkzwX2F1Vv9C8vhyoqvqtBe/z4qmksTPui5y1dfH0\nqcA9A6/vbbZJ0tgb1eJkq7HI2XKt6Z2ne/bsefh5r9ej1+ut5ekl6VFGdRfrqNqZmZlhZmZmqGMW\nGtVQzJ6q2tW8dihG0royqsXJRtXOoFZuUEryGOBrwAuBbwGfBy6pqrsWvM9glzS2RnUX66jvhm3t\nztMku4Cr6Y/Z76uqKxZ5j8EuSUNySQFJ6hiXFJAkGeyS1DUGuyR1jMEuSR1jsEtSxxjsktQxBrsk\ndYzBLkkdY7BLUscY7JLUMQa7JHWMwS5JHWOwS1LHGOyS1DEGuyR1jMEuSR1jsEtSxxjsktQxBrsk\ndYzBLkkdY7BLUscY7JLUMSsK9iS7k9yb5EvNY9eoCpMkLc8oeuxXVdU5zeMTI2hvzczMzLRdwqOM\nY00wnnVZ09JY09KNa13DGkWwZwRttGIc/xHHsSYYz7qsaWmsaenGta5hjSLYfy3JbUneneSUEbQn\nSVqBEwZ7kk8lOTjwuL3588XAXuDpVXU2cB9w1WoXLEk6vlTVaBpKpoAbq2rHMfaP5kSStMFU1VBD\n3ptWcrIk26rqvublS4E7RlWYJGl5VhTswJVJzgYeAmaB1664IknSioxsKEaSNB7W9M7TJFcmuauZ\nRfPhJFvX8vwLatmV5KtJ/jTJW9uqY6CeM5LckuQrzQXqN7Rd07wkJzU3oN3Qdi0ASU5J8qHme+kr\nSf7+GNT060nuaCYW/I8kW1qqY1+Sw0kODmw7NclNSb6W5JNrPXvtGDW1mgWL1TSw781JHkrypHGo\nKcnrm6/V7UmuWEpba72kwE3As5pZNH8GvG2Nzw/0gwp4F3AB8CzgkiTb26hlwI+BN1XVs4B/APzq\nGNQ0743AnW0XMeBq4I+q6pnAzwJ3tVlMkqcArwfOaSYPbAJe3lI576X/fT3ocuDmqvpp4BbW/v/d\nYjW1nQWL1USSM4DzgUNrXA8sUlOSHvBi4Geq6meA315KQ2sa7FV1c1U91Lz8HHDGWp5/wHOAP6uq\nQ1V1FPgAcFFLtQBQVfdV1W3N8x/SD6untlkTPPyN/ovAu9uuBaDp2T2vqt4LUFU/rqrvt1wWwGOA\nxyfZBDwO+GYbRVTVZ4AHFmy+CLimeX4N8JK2a2o7C47xdQL4HeBfrWUt845R078ArqiqHzfv+cul\ntNXmImCvAT7e0rmfCtwz8PpexiBE5yWZBs4G/le7lQB/840+Lhdjfgr4yyTvbYaHfj/JRJsFVdU3\ngf8M3A38BfDdqrq5zZoWeHJVHYZ+BwJ4csv1LNRmFjwsyYXAPVV1e9u1DHgG8Pwkn0tya5K/t5SD\nRh7sJ7ihaf49/xo4WlXXjvr8612Sk4HrgTc2Pfc2a/kl4HDzm0QYj+UjNgHnAL9bVecAP6I/1NCa\nJE+k3yueAp4CnJzkFW3WdALj8kN6bLKg6Ry8Hdg9uLmlcgZtAk6tqucCvwF8cKkHjVRVnX+8/Uku\npf+r/QtGfe4h/AVw5sDrM5ptrWp+jb8eeH9VfbTteoBzgQuT/CIwATwhyfuq6pUt1nQv/V7VF5rX\n1wNtX/x+EfD1qrofIMkfAD8PjEvH5XCS06vqcJJtwLfbLgjGJgvmnQVMA/87SehnwheTPKeq2vx6\n3QP8AUBVHWgu6p5WVd853kFrPStmF/1f6y+sqr9ay3MvcAD420mmmtkLLwfGYcbHe4A7q+rqtgsB\nqKq3V9WZVfV0+l+jW1oOdZohhXuSPKPZ9ELav7B7N/DcJD/RhMILafeC7sLfrm4ALm2evwpoo9Pw\niJrGJAserqmq7qiqbVX19Kr6KfodiGe3EOoL/+0+QvODr/me33yiUAegqtbsQf/q9yHgS81j71qe\nf0Etu4CvNTVd3lYdA/WcC/w1cBvw5ebrs6vtugbqOw+4oe06mlp+lv4P59vo92ZOGYOadtMP84P0\nL1BubqmOa+lfuP0r+j9wXg2cCtzcfL/fBDxxDGpqNQsWq2nB/q8DT2q7JvqjKu8Hbge+AJy3lLa8\nQUmSOsaPxpOkjjHYJaljDHZJ6hiDXZI6xmCXpI4x2CWpYwx2SeoYg12SOub/A8a6RblTLCDxAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff3d890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_score = [18.57570327,0.21705893,21.06000171,11.59554766,24.46765405,6.23420114,25.09754153,4.20497086,\n",
    "                10.07245453,9.34670079,2.10765594,8.74648553,1.69882435,0.1641645,5.34494152,2.42650813]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(16),sorted(select_score, reverse=True))\n",
    "plt.title('select score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the three classifiers I have tried, GaussianNB gives the best compared with SVC and RandomForestClassifier. For the GaussianNB, it has a precision of 0.433, a recall of 0.346. However, for example, SVC gives a recall score of 0.012, which is almost zero. This result is strange to me that both SVC and random forest do not work very well, and there must be some hyper parameters that need to be further tuned in order to make these two algorithms to work. I will keep trying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning models, there are some parameters that need to be set before the real training sessions, and these parameters are called hyper parameters [[wiki](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)].  Usually, to make the models work well with the data (fitting and prediction), these parameters need to be carefully chosen, the process of which is called parameter tuning. The choice of the hyper parameters is vital for the sucess of the model. For example, if one is using k-means to do an unsupervised clustering, the total number of clusters k need to be predefined. If this number is not chosen properly, then no matter how advanced your model is, the result will not be good. The algorithm I picked is naive bayes, and it does not need hyper parameters. But for the other two algorithms I tried, such as the random forest, I need to tune the min_samples_split, which represent minimum number of samples that can be used to do another branching. I used GridSearchCV to try different combinations of the hyper parameters, and pick the one giving the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model validation is a type of methods used to evaluate a trained model on a different set of data (validation set) in order to test the generalization power of the trained model. This validation procesure is very important, espectially for the prevention of overfitting. A very complicated model, or a model with too many parameters usually performs very well on the training set of data. However, these models tend to have very high variance, and cannot be generalized well to new data. Thus, validation is used to achieve a balance between model complexity and training performance, or bias-variance-tradeoff. Based on the size of the data set, different strategies should be used. If data is abundant, then one can split the training set into two parts, the first part is used for training, and the second part is used for validation. If data is not that abundant but also not rare, one can use cross validation. However, if data is really rare or the positive and negative samples are imbalanced, then one needs to use stratified split, which is the case in my project. **The reason to use function StratifiedShuffleSplit** is that the positive and negative samples in our data set are extremely skewed, only 19 out of 145 samples are positive. Thus, a normal splitting method can result in a even more skewed situation [[refer here](https://florianhartl.com/thoughts-on-machine-learning-dealing-with-skewed-classes.html)]. For each subgroup, 30% are randomly sampled as test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics I used are precision and recall. For the naive Bayes, I obtain a precision of 0.43, and a recall of 0.35. In the Enron case, a precision of 0.43 means that among 100 predicted pois, 43 of them are really pois; a recall of 0.35 means that if there are 100 true pois, only 35 of them are correctly identified as such."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
